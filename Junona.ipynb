{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pwielopolski/anaconda3/envs/datascience_extended/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/pwielopolski/anaconda3/envs/datascience_extended/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from costcla.metrics import cost_loss, savings_score\n",
    "from costcla.models import BayesMinimumRiskClassifier, ThresholdingOptimization\n",
    "from costcla.models import CostSensitiveDecisionTreeClassifier, CostSensitiveLogisticRegression\n",
    "from costcla.models import CostSensitiveRandomForestClassifier, CostSensitiveBaggingClassifier, CostSensitivePastingClassifier, CostSensitiveRandomPatchesClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS = -1\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cost_matrix(df, fp_cost, fn_cost, tp_cost, tn_cost):\n",
    "    # false positives, false negatives, true positives, true negatives\n",
    "    def generate_cost(df, cost):\n",
    "        return df[cost] if type(cost) == str else cost\n",
    "    \n",
    "    cost_matrix = np.zeros((df.shape[0], 4))\n",
    "    \n",
    "    cost_matrix[:, 0] = generate_cost(df, fp_cost)\n",
    "    cost_matrix[:, 1] = generate_cost(df, fn_cost)\n",
    "    cost_matrix[:, 2] = generate_cost(df, tp_cost)\n",
    "    cost_matrix[:, 3] = generate_cost(df, tn_cost)\n",
    "    \n",
    "    return cost_matrix\n",
    "\n",
    "\n",
    "def generate_rf_models():\n",
    "\n",
    "    max_depth = [None, 1, 2, 3, 4, 5]\n",
    "    n_estimatiors = [10, 50, 100, 200, 500]\n",
    "\n",
    "    rf_models = {\n",
    "        f'CI-GS_RandomForest-n_est_{n_est}_md_{md}': RandomForestClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_estimators=n_est,\n",
    "            max_depth=md,\n",
    "            n_jobs=N_JOBS\n",
    "        )\n",
    "        for n_est, md in itertools.product(n_estimatiors, max_depth)\n",
    "    }\n",
    "    return rf_models\n",
    "\n",
    "\n",
    "def generate_xgb_models():\n",
    "    \n",
    "    max_depth = [0, 1, 2, 3, 4, 5]\n",
    "    subsample = [0.5, 0.75, 1]\n",
    "    colsample_bytree = [0.5, 0.75, 1]\n",
    "\n",
    "    xgb_models = {\n",
    "        f'CI-GS_XGBoost-md_{md}_subs_{subs}_cs_bt_{cs_bt}': xgboost.XGBClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            verbosity=0,\n",
    "            max_depth=md,\n",
    "            subsample=subs,\n",
    "            colsample_bytree=cs_bt,\n",
    "            n_jobs=N_JOBS\n",
    "        )\n",
    "        for md, subs, cs_bt in itertools.product(max_depth, subsample, colsample_bytree)\n",
    "    }\n",
    "    return xgb_models\n",
    "\n",
    "\n",
    "def generate_cost_sensitive_ensemble(model, name):\n",
    "    \n",
    "    combinations = ['majority_voting', 'weighted_voting', 'stacking', 'stacking_proba', \n",
    "                    'stacking_bmr', 'stacking_proba_bmr', 'majority_bmr', 'weighted_bmr']\n",
    "    n_estimatiors = [10, 20, 30]\n",
    "    \n",
    "    cs_ensemble_models = {\n",
    "        f'ECSDT-GS_{name}_{combination}-n_est_{n_est}': model(\n",
    "            n_estimators=n_est,\n",
    "            combination=combination,\n",
    "            n_jobs=N_JOBS\n",
    "        )\n",
    "        for n_est, combination in itertools.product(n_estimatiors, combinations)\n",
    "    }\n",
    "    return cs_ensemble_models\n",
    "    \n",
    "\n",
    "\n",
    "def generate_models():\n",
    "    \n",
    "    csrfc = generate_cost_sensitive_ensemble(CostSensitiveRandomForestClassifier, \n",
    "                                             'CostSensitiveRandomForestClassifier')\n",
    "    csbc = generate_cost_sensitive_ensemble(CostSensitiveBaggingClassifier,\n",
    "                                           'CostSensitiveBaggingClassifier')\n",
    "    cspc = generate_cost_sensitive_ensemble(CostSensitivePastingClassifier,\n",
    "                                           'CostSensitivePastingClassifier')\n",
    "    csrpc = generate_cost_sensitive_ensemble(CostSensitiveRandomPatchesClassifier,\n",
    "                                            'CostSensitiveRandomPatchesClassifier')\n",
    "\n",
    "    gs_rf_models = generate_rf_models()\n",
    "    gs_xgb_models = generate_xgb_models()\n",
    "    \n",
    "    models = {\n",
    "        'CI-LogisticRegression': LogisticRegression(), \n",
    "        'CI-DecisionTree': DecisionTreeClassifier(random_state=RANDOM_STATE), \n",
    "        'CI-RandomForest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "        'CI-XGBoost': xgboost.XGBClassifier(random_state=RANDOM_STATE,verbosity=0),\n",
    "        'CST-CostSensitiveLogisticRegression': CostSensitiveLogisticRegression(),\n",
    "        'CST-CostSensitiveDecisionTreeClassifier': CostSensitiveDecisionTreeClassifier()\n",
    "    }\n",
    "    #models.update(csrfc)\n",
    "    #models.update(csbc)\n",
    "    #models.update(cspc)\n",
    "    #models.update(csrpc)\n",
    "    #models.update(gs_rf_models)\n",
    "    #models.update(gs_xgb_models)\n",
    "    \n",
    "    return models\n",
    "\n",
    "\n",
    "def create_model_summary(model, name, X, y, cost_matrix):\n",
    "    print(name)\n",
    "    if name.startswith('BMR'):\n",
    "        # BMR Model\n",
    "        model, bmr = model\n",
    "        y_hat_proba = model.predict_proba(X)\n",
    "        y_hat = bmr.predict(y_hat_proba, cost_matrix)\n",
    "    elif name.startswith('TO'):\n",
    "        # Threshold Optimized Model\n",
    "        model, threshold_opt = model\n",
    "        y_hat_proba = model.predict_proba(X)\n",
    "        y_hat = threshold_opt.predict(y_hat_proba)\n",
    "    elif name.startswith('ECSDT'):\n",
    "        y_hat = model.predict(X, cost_matrix)\n",
    "    else:\n",
    "        y_hat = model.predict(X)\n",
    "        \n",
    "        \n",
    "    return {\n",
    "        'Name': name,\n",
    "        'Accuracy': accuracy_score(y, y_hat),\n",
    "        'Precision': precision_score(y, y_hat),\n",
    "        'Recall': recall_score(y, y_hat),\n",
    "        'F1': f1_score(y, y_hat),\n",
    "        'Cost': cost_loss(y, y_hat, cost_matrix),\n",
    "        'Savings': savings_score(y, y_hat, cost_matrix)\n",
    "    }\n",
    "\n",
    "\n",
    "def create_bmr_model(model, name, X_val, y_val, calibration = True):\n",
    "    \n",
    "    y_hat_val_proba = model.predict_proba(X_val)\n",
    "\n",
    "    bmr = BayesMinimumRiskClassifier(calibration = calibration)\n",
    "    bmr.fit(y_val, y_hat_val_proba)\n",
    "    \n",
    "    prefix = 'BMR' + '_calibration_' if calibration else 'BMR_'\n",
    "    name = prefix + name\n",
    "    \n",
    "    return (name, (model, bmr))\n",
    "\n",
    "\n",
    "def create_threshold_optimized_model(model, name, X_train, y_train, cost_matrix_train, calibration = True):\n",
    "        \n",
    "    y_hat_train_proba = model.predict_proba(X_train)\n",
    "\n",
    "    threshold_opt = ThresholdingOptimization(calibration = calibration)\n",
    "    threshold_opt.fit(y_hat_train_proba, cost_matrix_train, y_train)\n",
    "    \n",
    "    prefix = 'TO' + '_calibration_' if calibration else 'TO_'\n",
    "    name = prefix + name\n",
    "    \n",
    "    return (name, (model, threshold_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPERATIONAL_COST = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/creditcard.csv')\n",
    "cost_matrix = create_cost_matrix(df, OPERATIONAL_COST, 'Amount', OPERATIONAL_COST, 0)\n",
    "\n",
    "X = df.drop(['Time', 'Amount', 'Class'], axis = 1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, cost_matrix_train, cost_matrix_test = train_test_split(X, y, cost_matrix, train_size = 0.5, stratify = y, random_state = RANDOM_STATE)\n",
    "X_val, X_test, y_val, y_test, cost_matrix_val, cost_matrix_test = train_test_split(X_test, y_test, cost_matrix_test, train_size = 0.33, stratify = y_test, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling\n",
    "\"\"\"\n",
    "X_train = pd.concat([X_train.reset_index(), pd.DataFrame(cost_matrix_train)], axis = 1).set_index('index')\n",
    "X_train['Class'] = y_train\n",
    "\n",
    "X_train = pd.concat([\n",
    "    X_train[X_train['Class'] == 0].sample(frac = 0.05, random_state=RANDOM_STATE),\n",
    "    X_train[X_train['Class'] == 1]\n",
    "])\n",
    "\n",
    "y_train = X_train['Class']\n",
    "cost_matrix_train = X_train[[0, 1, 2, 3]].values\n",
    "X_train = X_train.drop(['Class', 0, 1, 2, 3], axis = 1)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = generate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI-LogisticRegression\n",
      "CI-DecisionTree\n",
      "CI-RandomForest\n",
      "CI-XGBoost\n",
      "CST-CostSensitiveLogisticRegression\n",
      "CST-CostSensitiveDecisionTreeClassifier\n"
     ]
    }
   ],
   "source": [
    "def filter_model_names(models, value):\n",
    "    return [name for name in models.keys() if value in name]\n",
    "    \n",
    "\n",
    "standard_model_names = filter_model_names(models, 'GS_RandomForest') + ['CI-LogisticRegression', 'CI-DecisionTree', 'CI-RandomForest']\n",
    "cost_sensitive_model_names = filter_model_names(models, 'CST') + filter_model_names(models, 'ECSDT')\n",
    "xgb_model_names = filter_model_names(models, 'XGBoost')\n",
    "calibration_model_names = standard_model_names + xgb_model_names\n",
    "\n",
    "# Standard model training\n",
    "\n",
    "for name in standard_model_names:\n",
    "    print(name)\n",
    "    models[name].fit(X_train.values, y_train.values)\n",
    "\n",
    "    \n",
    "for name in xgb_model_names:\n",
    "    print(name)\n",
    "    models[name].fit(\n",
    "        X_train.values, y_train.values, \n",
    "        eval_set = [(X_val.values, y_val.values), (X_train.values, y_train.values)],\n",
    "        eval_metric = 'aucpr',\n",
    "        early_stopping_rounds = 50,\n",
    "        verbose = False\n",
    "    )       \n",
    "    \n",
    "    \n",
    "for name in cost_sensitive_model_names:\n",
    "    print(name)\n",
    "    models[name].fit(X_train.values, y_train.values, cost_matrix_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI-LogisticRegression\n",
      "CI-LogisticRegression\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d7676c15231a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mname_threshold_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_threshold_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_threshold_optimized_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_matrix_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalibration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalibration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname_threshold_opt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_threshold_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-dee6fdb0c4f4>\u001b[0m in \u001b[0;36mcreate_threshold_optimized_model\u001b[0;34m(model, name, X_train, y_train, cost_matrix_train, calibration)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mthreshold_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThresholdingOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalibration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalibration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mthreshold_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat_train_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_matrix_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'TO'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_calibration_'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalibration\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'TO_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/datascience_extended/lib/python3.7/site-packages/costcla/models/directcost.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y_prob, cost_mat, y_true)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mcost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/datascience_extended/lib/python3.7/site-packages/costcla/metrics/costs.py\u001b[0m in \u001b[0;36mcost_loss\u001b[0;34m(y_true, y_pred, cost_mat)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcost_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcost_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcost_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcost_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    # Threshold Optimization training\n",
    "\n",
    "    for name in calibration_model_names:\n",
    "        for calibration in [True]:\n",
    "            print(name)\n",
    "            model = models[name]\n",
    "            name_threshold_opt, model_threshold_opt = create_threshold_optimized_model(model, name, X_train.values, y_train.values, cost_matrix_train, calibration = calibration)\n",
    "            models[name_threshold_opt] = model_threshold_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI-LogisticRegression\n",
      "CI-LogisticRegression\n",
      "CI-DecisionTree\n",
      "CI-DecisionTree\n",
      "CI-RandomForest\n",
      "CI-RandomForest\n",
      "CI-XGBoost\n",
      "CI-XGBoost\n"
     ]
    }
   ],
   "source": [
    "# BMR training\n",
    "\n",
    "for name in calibration_model_names:\n",
    "    for calibration in [True, False]:\n",
    "        print(name)\n",
    "        model = models[name]\n",
    "        name_bmr, model_bmr = create_bmr_model(model, name, X_val.values, y_val.values, calibration = calibration)\n",
    "        models[name_bmr] = model_bmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI-LogisticRegression\n",
      "CI-DecisionTree\n",
      "CI-RandomForest\n",
      "CI-XGBoost\n",
      "CST-CostSensitiveLogisticRegression\n",
      "CST-CostSensitiveDecisionTreeClassifier\n",
      "TO_calibration_CI-LogisticRegression\n",
      "BMR_calibration_CI-LogisticRegression\n",
      "BMR_CI-LogisticRegression\n",
      "BMR_calibration_CI-DecisionTree\n",
      "BMR_CI-DecisionTree\n",
      "BMR_calibration_CI-RandomForest\n",
      "BMR_CI-RandomForest\n",
      "BMR_calibration_CI-XGBoost\n",
      "BMR_CI-XGBoost\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cost</th>\n",
       "      <th>F1</th>\n",
       "      <th>Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999182</td>\n",
       "      <td>6169.57</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>CI-LogisticRegression</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.594864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999151</td>\n",
       "      <td>5708.01</td>\n",
       "      <td>0.750769</td>\n",
       "      <td>CI-DecisionTree</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.625174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999465</td>\n",
       "      <td>5017.60</td>\n",
       "      <td>0.827119</td>\n",
       "      <td>CI-RandomForest</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.670511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999403</td>\n",
       "      <td>6621.24</td>\n",
       "      <td>0.809365</td>\n",
       "      <td>CI-XGBoost</td>\n",
       "      <td>0.902985</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.565205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.337204</td>\n",
       "      <td>163631.29</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>CST-CostSensitiveLogisticRegression</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-9.745133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.998952</td>\n",
       "      <td>4859.59</td>\n",
       "      <td>0.640288</td>\n",
       "      <td>CST-CostSensitiveDecisionTreeClassifier</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.539394</td>\n",
       "      <td>0.680887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.999141</td>\n",
       "      <td>6077.90</td>\n",
       "      <td>0.738854</td>\n",
       "      <td>TO_calibration_CI-LogisticRegression</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.703030</td>\n",
       "      <td>0.600884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.997432</td>\n",
       "      <td>4345.56</td>\n",
       "      <td>0.366925</td>\n",
       "      <td>BMR_calibration_CI-LogisticRegression</td>\n",
       "      <td>0.319820</td>\n",
       "      <td>0.430303</td>\n",
       "      <td>0.714641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.996908</td>\n",
       "      <td>4499.39</td>\n",
       "      <td>0.312354</td>\n",
       "      <td>BMR_CI-LogisticRegression</td>\n",
       "      <td>0.253788</td>\n",
       "      <td>0.406061</td>\n",
       "      <td>0.704540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.998669</td>\n",
       "      <td>5585.96</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>BMR_calibration_CI-DecisionTree</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>0.633188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.998742</td>\n",
       "      <td>5568.46</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>BMR_CI-DecisionTree</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>0.634337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.998679</td>\n",
       "      <td>4083.00</td>\n",
       "      <td>0.536765</td>\n",
       "      <td>BMR_calibration_CI-RandomForest</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.442424</td>\n",
       "      <td>0.731883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.996803</td>\n",
       "      <td>4435.51</td>\n",
       "      <td>0.326711</td>\n",
       "      <td>BMR_CI-RandomForest</td>\n",
       "      <td>0.256944</td>\n",
       "      <td>0.448485</td>\n",
       "      <td>0.708735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.995252</td>\n",
       "      <td>4034.62</td>\n",
       "      <td>0.248756</td>\n",
       "      <td>BMR_calibration_CI-XGBoost</td>\n",
       "      <td>0.171233</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.735060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.995808</td>\n",
       "      <td>3602.43</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>BMR_CI-XGBoost</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.763440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy       Cost        F1                                     Name  \\\n",
       "0   0.999182    6169.57  0.734694                    CI-LogisticRegression   \n",
       "1   0.999151    5708.01  0.750769                          CI-DecisionTree   \n",
       "2   0.999465    5017.60  0.827119                          CI-RandomForest   \n",
       "3   0.999403    6621.24  0.809365                               CI-XGBoost   \n",
       "4   0.337204  163631.29  0.003121      CST-CostSensitiveLogisticRegression   \n",
       "5   0.998952    4859.59  0.640288  CST-CostSensitiveDecisionTreeClassifier   \n",
       "6   0.999141    6077.90  0.738854     TO_calibration_CI-LogisticRegression   \n",
       "7   0.997432    4345.56  0.366925    BMR_calibration_CI-LogisticRegression   \n",
       "8   0.996908    4499.39  0.312354                BMR_CI-LogisticRegression   \n",
       "9   0.998669    5585.96  0.501961          BMR_calibration_CI-DecisionTree   \n",
       "10  0.998742    5568.46  0.516129                      BMR_CI-DecisionTree   \n",
       "11  0.998679    4083.00  0.536765          BMR_calibration_CI-RandomForest   \n",
       "12  0.996803    4435.51  0.326711                      BMR_CI-RandomForest   \n",
       "13  0.995252    4034.62  0.248756               BMR_calibration_CI-XGBoost   \n",
       "14  0.995808    3602.43  0.272727                           BMR_CI-XGBoost   \n",
       "\n",
       "    Precision    Recall   Savings  \n",
       "0    0.837209  0.654545  0.594864  \n",
       "1    0.762500  0.739394  0.625174  \n",
       "2    0.938462  0.739394  0.670511  \n",
       "3    0.902985  0.733333  0.565205  \n",
       "4    0.001565  0.600000 -9.745133  \n",
       "5    0.787611  0.539394  0.680887  \n",
       "6    0.778523  0.703030  0.600884  \n",
       "7    0.319820  0.430303  0.714641  \n",
       "8    0.253788  0.406061  0.704540  \n",
       "9    0.711111  0.387879  0.633188  \n",
       "10   0.771084  0.387879  0.634337  \n",
       "11   0.682243  0.442424  0.731883  \n",
       "12   0.256944  0.448485  0.708735  \n",
       "13   0.171233  0.454545  0.735060  \n",
       "14   0.194805  0.454545  0.763440  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'outputs/' + 'Training-results-' + datetime.now().isoformat('-', timespec = 'minutes') + '.csv'\n",
    "\n",
    "\n",
    "temp = []\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        temp.append(create_model_summary(model, name, X_test.values, y_test.values, cost_matrix_test))\n",
    "    except:\n",
    "        pass\n",
    "results = pd.DataFrame(temp)\n",
    "\n",
    "\n",
    "#results = pd.DataFrame([create_model_summary(model, name, X_test.values, y_test.values, cost_matrix_test) for name, model in models.items()])\n",
    "#results.to_csv(filepath, index=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cost</th>\n",
       "      <th>F1</th>\n",
       "      <th>Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Savings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.337204</td>\n",
       "      <td>163631.29</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>CST-CostSensitiveLogisticRegression</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-9.745133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999403</td>\n",
       "      <td>6621.24</td>\n",
       "      <td>0.809365</td>\n",
       "      <td>CI-XGBoost</td>\n",
       "      <td>0.902985</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.565205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999182</td>\n",
       "      <td>6169.57</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>CI-LogisticRegression</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.594864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.999141</td>\n",
       "      <td>6077.90</td>\n",
       "      <td>0.738854</td>\n",
       "      <td>TO_calibration_CI-LogisticRegression</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.703030</td>\n",
       "      <td>0.600884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999151</td>\n",
       "      <td>5708.01</td>\n",
       "      <td>0.750769</td>\n",
       "      <td>CI-DecisionTree</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.625174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.998669</td>\n",
       "      <td>5585.96</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>BMR_calibration_CI-DecisionTree</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>0.633188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.998742</td>\n",
       "      <td>5568.46</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>BMR_CI-DecisionTree</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>0.634337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999465</td>\n",
       "      <td>5017.60</td>\n",
       "      <td>0.827119</td>\n",
       "      <td>CI-RandomForest</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.670511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.998952</td>\n",
       "      <td>4859.59</td>\n",
       "      <td>0.640288</td>\n",
       "      <td>CST-CostSensitiveDecisionTreeClassifier</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.539394</td>\n",
       "      <td>0.680887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.996908</td>\n",
       "      <td>4499.39</td>\n",
       "      <td>0.312354</td>\n",
       "      <td>BMR_CI-LogisticRegression</td>\n",
       "      <td>0.253788</td>\n",
       "      <td>0.406061</td>\n",
       "      <td>0.704540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.996803</td>\n",
       "      <td>4435.51</td>\n",
       "      <td>0.326711</td>\n",
       "      <td>BMR_CI-RandomForest</td>\n",
       "      <td>0.256944</td>\n",
       "      <td>0.448485</td>\n",
       "      <td>0.708735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.997432</td>\n",
       "      <td>4345.56</td>\n",
       "      <td>0.366925</td>\n",
       "      <td>BMR_calibration_CI-LogisticRegression</td>\n",
       "      <td>0.319820</td>\n",
       "      <td>0.430303</td>\n",
       "      <td>0.714641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.998679</td>\n",
       "      <td>4083.00</td>\n",
       "      <td>0.536765</td>\n",
       "      <td>BMR_calibration_CI-RandomForest</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.442424</td>\n",
       "      <td>0.731883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.995252</td>\n",
       "      <td>4034.62</td>\n",
       "      <td>0.248756</td>\n",
       "      <td>BMR_calibration_CI-XGBoost</td>\n",
       "      <td>0.171233</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.735060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.995808</td>\n",
       "      <td>3602.43</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>BMR_CI-XGBoost</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.763440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy       Cost        F1                                     Name  \\\n",
       "4   0.337204  163631.29  0.003121      CST-CostSensitiveLogisticRegression   \n",
       "3   0.999403    6621.24  0.809365                               CI-XGBoost   \n",
       "0   0.999182    6169.57  0.734694                    CI-LogisticRegression   \n",
       "6   0.999141    6077.90  0.738854     TO_calibration_CI-LogisticRegression   \n",
       "1   0.999151    5708.01  0.750769                          CI-DecisionTree   \n",
       "9   0.998669    5585.96  0.501961          BMR_calibration_CI-DecisionTree   \n",
       "10  0.998742    5568.46  0.516129                      BMR_CI-DecisionTree   \n",
       "2   0.999465    5017.60  0.827119                          CI-RandomForest   \n",
       "5   0.998952    4859.59  0.640288  CST-CostSensitiveDecisionTreeClassifier   \n",
       "8   0.996908    4499.39  0.312354                BMR_CI-LogisticRegression   \n",
       "12  0.996803    4435.51  0.326711                      BMR_CI-RandomForest   \n",
       "7   0.997432    4345.56  0.366925    BMR_calibration_CI-LogisticRegression   \n",
       "11  0.998679    4083.00  0.536765          BMR_calibration_CI-RandomForest   \n",
       "13  0.995252    4034.62  0.248756               BMR_calibration_CI-XGBoost   \n",
       "14  0.995808    3602.43  0.272727                           BMR_CI-XGBoost   \n",
       "\n",
       "    Precision    Recall   Savings  \n",
       "4    0.001565  0.600000 -9.745133  \n",
       "3    0.902985  0.733333  0.565205  \n",
       "0    0.837209  0.654545  0.594864  \n",
       "6    0.778523  0.703030  0.600884  \n",
       "1    0.762500  0.739394  0.625174  \n",
       "9    0.711111  0.387879  0.633188  \n",
       "10   0.771084  0.387879  0.634337  \n",
       "2    0.938462  0.739394  0.670511  \n",
       "5    0.787611  0.539394  0.680887  \n",
       "8    0.253788  0.406061  0.704540  \n",
       "12   0.256944  0.448485  0.708735  \n",
       "7    0.319820  0.430303  0.714641  \n",
       "11   0.682243  0.442424  0.731883  \n",
       "13   0.171233  0.454545  0.735060  \n",
       "14   0.194805  0.454545  0.763440  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('Savings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- Second jupyter notebook with results analysis\n",
    "- Cross Validation (?)\n",
    "- Rewrite this notebook to script?\n",
    "- Make whole experiment with respect to differenct Operational Cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
