\documentclass{book}

\usepackage{amsmath}
\usepackage{listings}

\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{makecell}
\setcellgapes{5pt}

\usepackage[utf8]{inputenc}
\usepackage{polski}

\title{Detekcja oszustw z wykorzystaniem metod wrażliwych na koszt}
\author{Patryk Wielopolski}

\begin{document}
	
	\newcommand{\htx}{h_{\theta}(\boldsymbol{x_i})}
	\newcommand{\es}{\mathcal{S}}
	\newcommand{\ef}{\mathcal{F}}
	\newcommand{\iks}{\boldsymbol{x}}
	\newcommand{\bes}{\boldsymbol{S}}
	\newcommand{\yht}[1]{y_i^{(#1)}}
	
	\newenvironment{talign}
	{\align}
	{\endalign}
	
	\newenvironment{talign*}
	{\csname align*\endcsname}
	{\endalign}

\maketitle

\chapter{Wstęp}
	- Rosnąca ilość transakcji kartami kredytowymi
	- Rosnący poziom fraudów na świecie
	
	- Flow transakcji oraz umiejscowienie systemu do detekcji fraudów
	- Aktualna sytuacja if-then + predicitve models
	
	If-then:
	- więcej niż 4 wypłaty z bankomatu w ciągu godziny
	- więcej niż 2 transakcje w ciągu 5 minut
	- transakcja w sklepie karta a następna zaraz w internecie
	
	Jeżeli więcej niż 1 reguła jest spełniona to odmowa transakcji. Pojawiają się problemy z niewykrywaniem nowych reguł oraz możliwe jest tworzenie tylko prostych reguł. Z drugiej strony są one proste do implementacji oraz interpretacji.
	

\chapter{Wprowadzenie teoretyczne}

W tej części zostaną wprowadzone wszelkie potrzebne miary skuteczności modeli oraz modele predykcyjne, które zostaną wykorzystane do przeprowadzenia eksperymentu. 

Modele predykcyjne zostały podzielone na dwie kategorie: standardowe oraz wrażliwe na koszt. Pierwsze z nich są powszechnie wykorzystywane w standardowych aplikacjach. Drugie z nich dzielą się na dwie podkategorie - \textit{Cost Sensitive Training} oraz \textit{Cost Sensitive Classification}.

\section{Miary skuteczności modeli}

\subsection{Macierz pomyłek}

W tej sekcji zdefiniujemy macierz pomyłek.
\begin{table}[h]
	\begin{center}
		\makegapedcells
		\begin{tabular}{cc|cc}
			\multicolumn{2}{c}{}     &   \multicolumn{2}{c}{Predykcja} \\
			&            &   Oszustwo &   Normalna     \\ 
			\cline{2-4}
			\multirow{2}{*}{\rotatebox[origin=c]{90}{Prawda}} & Oszustwo   & TP         & FN              \\
			& Normalna   & FP         & TN              \\ 
			\cline{2-4}
		\end{tabular}
	\end{center}
	\caption{Macierz pomyłek}
	\label{macierz-pomylek}
\end{table}


Na podstawie podanej macierzy pomyłek w tabeli \ref{macierz-pomylek} definiujemy następujące miary skuteczności modeli:

$$ \text{Skuteczność} = \frac{TP + TN}{TP + FP + FN + TN} $$
$$ \text{Precyzja} = \frac{TP}{TP + FP} $$
$$ \text{Czułość}= \frac{TP}{TP + FN} $$
$$ \text{F1 Score} = 2 \cdot \frac{\text{Precyzja} \cdot \text{Czułość}}{\text{Precyzja} + \text{Czułość}} $$

\subsection{Miary skuteczności modeli wrażliwe na koszt}

	Motywacją do powstania miar wrażliwych na koszt jest rzeczywista ewaluacja modeli. Podstawowe metryki nie uwzględniają różnicy w kosztach pomyłki dla fp i fn. Ponadto koszt fraudów znacząco różni się w zależności od przypadku.

	W celu wprowadzenia potrzebnych metryk potrzebujemy wprowadzić tzw. macierz kosztu, która jest zaprezentowana w tabeli \ref{macierz-kosztu}, gdzie poszczególne komórki oznacza odpowiadające wartość kosztu predykcji. 
	\begin{table}[h]
		\begin{center}
			\makegapedcells
			\begin{tabular}{cc|cc}
				\multicolumn{2}{c}{}     &   \multicolumn{2}{c}{Predykcja} \\
				&            &   Oszustwo &   Normalna     \\ 
				\cline{2-4}
				\multirow{2}{*}{\rotatebox[origin=c]{90}{Prawda}} & Oszustwo   & $C_{TP_{i}}$         & $C_{FN_{i}}$              \\
				& Normalna   & $C_{FP_{i}}$         & $C_{TN_{i}}$              \\ 
				\cline{2-4}
			\end{tabular}
		\end{center}
		\caption{Macierz kosztu}
		\label{macierz-kosztu}
	\end{table}
	Następnie definiujemy następującą wartość:
	$$ \text{Koszt}(f(\iks_{i}^{*})) = y_i (c_i C_{TP_i} + (1-c_i)C_{FN_i}) + (1-y_i)(c_i C_{FP_i} + (1-c_i)C_{TN_i}) \text{,}$$
	gdzie 
	\begin{itemize}
		\item $\iks_{i}^{*} = [\iks_i, C_{TP_{i}}, C_{FP_{i}}, C_{FN_{i}}, C_{TN_{i}}]$ - wektor zawierający wartości cech i-tej obserwacji rozszerzony o koszt klasyfikacji
		\item $C_{\cdot}$ - koszt klasyfikacji i-tej obserwacji
		\item $f(\cdot)$ - model predykcyjny
		\item $y_i$ - prawdziwa wartość i-tej obserwacji
		\item $c_i$ - predykcja dla i-tej obserwacji
	\end{itemize}{}
    Następnie wprowadzamy następujące miary skuteczności modeli:
	\begin{equation}
		\text{Koszt całkowity}(f(\boldsymbol{S})) = \sum_{i=1}^{N}\text{Cost}(f(\boldsymbol{x}_{i}^{*}))
	\end{equation} 
	\begin{equation}
		\text{Oszczędności} = \frac{\text{Koszt}_{l}(\bes) - \text{Koszt}(f(\bes))}{\text{Koszt}_{l}(\bes)}
	\end{equation}
	gdzie
	\begin{itemize}
		\item $ \bes $ - data set
		\item $ \text{Koszt}_l = min\{\text{Cost}(f_{0}(\bes), \text{Koszt}(f_{1}(\bes)\} $
		\item $ f_{a}(\bes) = \boldsymbol{a} $ gdzie $a \in \{0,1\}$
	\end{itemize}{}
	Wartość $ f_{a}(\bes)$ możemy rozumieć jako przypadek naiwnego modelu, który wszystkim obserwacjom przyznaje wartość $a$. Natomiast $ \text{Koszt}_l $ oznacza wybranie naiwnego klasyfikatora, który generuje mniejsze koszty. Zatem ostatecznie Oszczędności możemy rozumieć jako procentową wartość o ile testowany model jest lepszy od naiwnego klasyfikatora.
	
	% TODO: Analiza wartości minimalnych oraz maksymalnych Kosztu całkowitego oraz Oszczędności. 

\section{Standardowe modele}

	% TODO: Kilka słów o MLu w ogólności
	
	With judicious choices for yi, we may express a variety of tasks, such as regression, classification, and ranking. The task of training the model amounts to finding the best parameters that best fit the training data xi and labels yi
	
	. In order to train the model, we need to define the objective function to measure how well the model fit the training data.
	
	A salient characteristic of objective functions is that they consist two parts: training loss and regularization term:

	
	where L
	is the training loss function, and is the regularization term. The training loss measures how predictive our model is with respect to the training data. A common choice of L is the mean squared error, which is given by

\subsection{Regresja logistyczna}

	Regresja logistyczna należy do jednego z najbardziej podstawowych modeli statystycznych używanych do problemów klasyfikacyjnych. 
	\begin{equation}
		\hat{p} = P(y=1|\boldsymbol{x_i}) = h_{\theta}(\boldsymbol{x_i}) = g\left(\sum_{j=1}^k \theta^{(j)}x_i^{(j)} \right)
	\end{equation} 
	Standardowa funkcja straty przyjmuje następującą postać:
	$$ J(\theta) = \frac{1}{N} \sum_{i=1}^N J_i(\theta) $$
	gdzie funkcja $g(z)$ jest funkcją łączącą typu \textit{logit} i przyjmuje postać 
	$$ g(z) = \frac{1}{(1+e^{-z})} $$
	Natomiast 
	\begin{equation}
	\label{c-e}
		J_i(\theta) = -y_i log(h_{\theta}(\boldsymbol{x_i})) - (1-y_i) log(1 - h_{\theta}(\boldsymbol{x_i}))
	\end{equation}
	$$  $$
	 to standardowa entropia krzyżowa.

	% Analiza kosztów w regresji logistycznej

    Standard costs:
	$$
	J_i(\theta) \approx \left\{
	\begin{array}{rl}
	0, &\mbox{if $y_i \approx \htx$}, \\
	\infty, &\mbox{if $y_i \approx (1 - \htx)$}.
	\end{array}{}
	\right.
	$$
	
	Thus
	
	$$ C_{TP_i} = C_{TN_i} \approx 0 $$
	$$ C_{FP_i} = C_{FN_i} \approx \infty $$

	Wytrenowany, aby minimalizować błąd klasyfikacji, a ewaluowany na metryce kosztu.

\subsection{Drzewo decyzyjne}
\label{drzewo}

	Drzewo klasyfikacyjne to przykład jednego z rodzaju drzew decyzyjnych, którego celem jest znalezienie najlepszego rozróżnienia pomiędzy klasami. W ogólności drzewo decyzyjne składa się z zestawu reguł.
	
	Drzewo składa się z węzłów, które są reprezentowane przez parę $(\iks^j, l^j)$, która oznacza podział zbioru obserwacji $\es$ na dwa zbiory: $\es^{l}$ oraz $\es^{r}$ względem wektora obserwacji $\iks$ oraz progu decyzyjnego $\l^j$ w następujący sposób:
	$$ \es^l = \{ \iks^* : \iks^* \in \es \land x^j_i \leq l^j \} \text{,} $$
	$$ \es^r = \{ \iks^* : \iks^* \in \es \land x^j_i > l^j \} \text{,} $$
	gdzie $\iks^j$ reprezentuje $j$-ty atrybut wektora $\iks$. Ponadto $\l^j$ jest wartością taką, że $\min{\iks^j} \leq l^j < \max{\iks^j}$. Ponadto warto zauważyć, że $\es^l \cup \es^r = \es$, co oznacza, że nasz podział rozdziela wektor obserwacji na dokładnie dwa rozłączne zbiory.
	Po znalezieniu optymalnego podziału zliczamy ilość pozytywnych próbek:
	$$ \es_1  = \{ \iks^* : \iks^* \in \es \land y_i = 1 \} \text{,} $$
	a następnie zliczamy procent pozytywnych próbek jako:
	$$ \pi_1 = \frac{|\es_1|}{|\es|} \text{.}$$
	Następnie dla każdego z liści jest obliczana wielkość jego zanieczyszczenia.
	\begin{itemize}
		\item Misclassification: $I_m(\pi_1) = 1 - \max(\pi_1, 1 - \pi_1)$
		\item Entropy: $I_e(\pi_1) = -\pi_1 \log(\pi_1) - (1 - \pi_1) \log (1 - \pi_1)$
		\item Gini: $I_g(\pi_1) = 2 \pi_1 (1 - \pi_1)$
	\end{itemize}{}
	Następnie dla każdego proponowanego podziału dla danej reguły $(\iks^j, l^j)$ liczony jest przyrost czystości w następujący sposób:
	$$ \text{Gain}(\iks^j, l^j) = I(\pi_1) - \frac{|\es^l|}{|\es|} I(\pi_1^l) - \frac{|\es^r|}{|\es|} I(\pi_1^r) \text{,}$$
	gdzie $I(\pi_1)$ może być dowolną z zaproponowanych miar zanieczyszczenia.
	Ostatecznie wybiera się ten podział, który maksymalizuje przyrost czystości, a następnie dzieli się zbiór $\es$ na podzbiory $\es^l$ i $\es^r$.
	W taki sposób jest pokonywany pojedynczy podział zbioru dla konkretnego węzła. Całe drzewo tworzy się poprzez kolejne podziały węzłów aż do momentu dotarcia przez algorytm do kryterium stopu.
	
	% Dopisać kryteria stopu?
	% Przycinanie drzew 

\subsection{Las losowy}
	Kolejne modele są przedstawicielami szerokiej klasy metod \textit{ensemble}, których celem jest złożenie predykcji wielu klasyfikatorów bazowych, aby poprawić generalizację pojedynczego estymatora. Wśród nich wyróżniamy dwie główne kategorie. Pierwsza z nich to metody uśredniania, które polegają na zbudowaniu wielu niezależnych klasyfikatorów, a następnie uśrednianie wyników predykcji. Przedstawicielem tej kategorii jest las losowy. Natomiast druga polega na iteracyjnym budowaniu kolejnych modeli, które próbują zredukować obciążenie poprzednika. Bardzo powszechnie znanym reprezentantem jest algorytm XGBoost, którym zajmiemy się w następnym podrozdziale.
		
	Metody \textit{ensemble} wykorzystują metody próbkowania w celu utworzenia różnych klasyfikatorów bazowych, aby następnie dokonać ostatecznej predykcji. Metody te są używane, aby zredukować wariancję klasyfikatora bazowego (zazwyczaj drzewa decyzyjnego) poprzez losowe dobieranie próbki i/lub zmiennych, na których model będzie uczony. W wielu przypadkach stworzenie modelu opartego o \textit{bagging} jest znacznie prostsze, ponieważ wymaga jedynie zmiany próbkowania danych bez naruszania modelu bazowego, natomiast metody typu \text{boosting} wymagają zmiany całego algorytmu. Z licznych obserwacji wynika, że pierwsza z metod dużo lepiej radzi sobie mają jako bazowe klasyfikatory złożone modele, w przeciwieństwie do drugiej, która zazwyczaj najlepiej performuje wykorzystując proste modele (np. płytkie drzewa decyzyjne, tzn. o małej głębokości).
	
	% TODO: Złączyć oba opisy w jeden.
	
	Przykładowe metody losowania próbek do modeli bazowych:
	\begin{itemize}
		\item \textit{Pasting} - losowanie obserwacji bez powtórzeń
		\item \textit{Bagging} - losowanie obserwacji z powtórzeniami
		\item \textit{Random Subspaces} - losowanie podzbioru zmiennych
		\item \textit{Random Patches} - losowanie podzbioru zmiennych oraz obserwacji 
	\end{itemize}
	
	
	W przypadku lasu losowego proces losowania próbek jest podzielony na dwie fazy. Pierwsza z nich polega na próbkowaniu z powtórzeniami obserwacji ze zbioru treningowego dla każdego z osobnych estymatorów bazowych. Następnie podczas fazy tworzenia kolejnych węzłów w drzewach wybierany jest losowy podzbiór zmiennych, które mogą być w tym kroku wykorzystane. 
	
	Celem tych dwóch różnych źródeł losowości jest redukcja wariancji lasu. Pojedyncze drzewa mają tendencję do zbytniego dopasowywania się do danych, zatem losowanie poszczególnych zmiennych w każdym kolejnym węźle pomaga to zredukować. Natomiast losowanie różnych próbek do każdego z klasyfikatorów pozwala na stworzenie lekko odmiennych modeli bazowych.

\subsection{XGBoost}
	Tak jak wspomnieliśmy w poprzednim rozdziale algorytm XGBoost jest przykładem klasyfikatora, który w iteracyjny sposób tworzy kolejne bazowe klasyfikatory. W przypadku tego algorytmu jako klasyfikator bazowy wykorzystujemy implementację drzew decyzyjnych typu CART, które nieznacznie różnią się od standardowych drzew decyzyjnych opisywanych w \ref{drzewo}, ponieważ liść drzewa jest rozszerzony o wartość rzeczywistą, która reprezentuje decyzję modelu. Ponieważ jest to złożenie wielu klasyfikatorów, to możemy zapisać nasz model w następującej postaci:
	$$ \hat{y_i} = \sum_{k=1}^K f_k(x_i) \text{,} f_k \in \ef \text{,} $$
	gdzie $K$ oznacza liczbę drzew, $f$ funkcje z przestrzeni $\ef$ wszystkich możliwych drzew CART.
	Zatem funkcją, którą będziemy optymalizować przyjmuje następującą postać:
	\begin{equation}
	\label{Obj}
		\text{Obj}(\theta) = \sum_{i=1}^{n} l(y_i, \yht{t}) + \sum_{k=1}^{K} \Omega(f_k)
	\end{equation}
	W przypadku klasyfikacji przyjmujemy tak samo jak poprzednio funkcję entropii krzyżowej (\ref{c-e}).
	Patrząc na postać modelu nie różni się ona niczym od lasu losowego. Zatem różnica między tymi modelami polega na sposobie trenowania drzew, który pokrótce opiszemy.
	
	Ponieważ naszym modelem bazowym jest drzewo, to nie jesteśmy w stanie wprost rozwiązać zagadnienia optymalizacyjnego poprzez obliczenie gradientu funkcji i iteracyjne znalezienie rozwiązania. W tym przypadku posłużymy się treningiem addytywnym, który polega na iteracyjnym poprawianiem błędów z poprzednich modeli poprzez odpowiednie przydzielanie wag próbkom w kolejnych krokach algorytmu. 
	Oznaczmy wartość predykcji w kroku $t$ jako $\yht{t}$.
	
	 $$ \yht{0} = 0 $$
	 $$ \yht{1} = f_1(x_i)  = \yht{0} + f_1(x_i) $$
	 $$ \yht{2} = f_1(x_i) + f_2(x_i) = \yht{1} + f_2(x_i) $$
	 $$ ... $$
	 $$ \yht{t} = \sum_{k=1}^{t} f_k(x_i) = \yht{t-1} + f_t(x_i) $$
	 
	 Pozostaje zagadnienie jakie drzewo chcemy wybrać w każdym z kroków. Oczywiście takie, które optymalizuje naszą funkcję Obj. Korzystając z powyższych wzorów oraz \ref{Obj} otrzymujemy następującą postać tej funkcji:
	 $$ \sum_{i=1}^{n} l(y_i, \yht{t-1} + f_t(x_i)) + \Omega(f_t) + \text{constant .}$$
	 Korzystając z rozwinięcia szeregu Taylora dla funkcji straty otrzymujemy ogólny wzór:
	 $$ \text{Obj}^{(t)} = \sum_{i=1}^{n} [l(y_i, \yht{t-1}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t) + \text{constant ,} $$
	 gdzie 
	 $$ g_i = \partial_{\yht{t-1}} l(y_i, \yht{t-1}) $$
	 $$ h_i = \partial^2_{\yht{t-1}} l(y_i, \yht{t-1}) $$
	 Zatem po redukcji stałych, które są nieistotne z punktu widzenia optymalizacji otrzymujemy:
	 $$ \sum_{i=1}^{n} [g_i f_t(x_i) + \frac{1}{2} h_i f_t(x_i)] + \Omega(f_t) $$

\section{Cost Dependent Classification}
	
	\subsection{Optymalizacja progu}
	
	
	
	\subsection{Bayesian Minimum Risk}
	
	Risk associated with predictions:
	
	$$ R(p_f|x) = L(p_f|y_f)P(p_f|x) + L(p_f|y_l)P(y_l|x) $$
	$$ R(p_l|x) = L(p_l|y_l)P(p_l|x) + L(p_l|y_f)P(y_f|x) $$
	
	Classification threshold:
	
	$$ R(p_f|x) \leq R(p_l|x)$$
	
	Where:
	
	\begin{itemize}
		\item $P(p_f|x)$, $P(p_l|x)$ - estimated probability of fraud/legimate transaction
		\item $L(p_{i}|y_{j})$ and $i,j \in \{l,f\}$ - loss function
	\end{itemize}{}
	Exact formula:
	
	$$ P(p_f|x) \ge \frac{L(p_f|y_l) - L(p_l|y_l)}{L(p_l|y_f) - L(p_f|y_f) - L(p_l|y_l) + L(p_f|y_l)}$$
	
	After reformulation:
	
	$$ p \ge \frac{C_{FP} - C_{TN}}{C_{FN} - C_{TP} - C_{TN} + C_{FP}}$$

	\section{Cost Sensitive Training}
	
		Pierwszą podgrupą metod wrażliwych na koszt jest \textit{Cost Sensitive Trainig}. Są to metody, które 
	
	\subsection{Regresja logistyczna wrażliwa na koszt}
	
	    Actual costs:
	
		$$
		J^c_i(\theta)=\left\{
		\begin{array}{rl}
		C_{TP_i}, &\mbox{if $y_i = 1$ and $\htx \approx 1$}, \\
		C_{TN_i}, &\mbox{if $y_i = 0$ and $\htx \approx 0$}, \\
		C_{FP_i}, &\mbox{if $y_i = 0$ and $\htx \approx 1$}, \\
		C_{FN_i}, &\mbox{if $y_i = 1$ and $\htx \approx 0$}.
		\end{array}
		\right.
		$$
		
		Cost sensitive loss function:
		\begin{talign*}
			J^c(\theta) &= \frac{1}{N} \sum_{i=1}^{N} \bigg( y_i \Big( \htx C_{TP_i} + (1 - \htx)C_{FN_i} \Big) \\
			&+ (1-y_i) \Big( \htx C_{FP_i} + (1 - \htx)C_{TN_i} \Big) \bigg)
		\end{talign*}
	
	\subsection{Drzewo decyzyjne wrażliwe na koszt}
	
	
	
		
		Cost Sensitive impurity measure:
		$ I_c(\es) = min \left\{ Cost(f_0(\es)), Cost(f_1(\es)) \right\}$
		
		$$ f(\es) =  \left\{
			\begin{array}{rl}
				0, &\mbox{jeżeli $\text{Cost}(f_0(\es)) \leq \text{Cost}(f_1(\es))$}, \\
				1, &\mbox{w przeciwnym wypadku}.
			\end{array}{}
		\right.
		$$
	
	

\chapter{Eksperyment}

Celem eksperymentu jest zbadanie jaki wpływ mają na miarę F1 oraz oszczędności mają poszczególne algorytmy.

Do eksperymentu zostanie wykorzystany zbiór danych Credit Card Fraud Detection zawierający 284,807 transakcji w tym zaledwie 492 oszustw. Tabela składa się z 30 kolumn, w tym 28 z nich są to nienazwane, zanonimizowane zmienne, które były wcześniej poddane transformacji PCA (\textit{ang. Principal Component Analysis}), dodatkowo posiadamy informacje dot. czasu transakcji oraz kwoty. 

Mimo tego, że dane są zanonimizowane można mieć pewne intuicje na temat tego jakie zmienne zostały użyte z zbiorze danych. 
Raw data:
- ID klienta, data transakcji, kwota, lokalizacja, typ transakcji (internet, płatność w sklepie, wypłata z bankomatu), rodzaj transakcji (linie lotnicze, hotel, wypożyczalnia samochodów), fraud, wiek klienta, kraj zamieszkania, kod pocztowy, typ karty
Na podstawie ref zmienne, które wykorzystuje się do tego typu problemów to:
- agregaty czasowe, np. ilość transakcji dla tego samego klienta w ciągu ostatnich 6 godzin, suma transakcji z ostatnich 7 dni itp.
W ogólności są to agregaty klient/karta kredytowa x typ transakcji/sklep/kategorai sklepu/kraj x ostatnie godziny/dni/tygodnie/miesiące x ilość/średnia/suma


Rozkład kwoty...

Eksperyment został przeprowadzony w następujący sposób:
50-krotnie dzielimy zbiór danych w proporcjach 50:17:33 na zbiór treningowy, walidacyjny oraz testowy. Następnie uczymy wszystkie modele na zbiorze treningowym. Dla modelu XGBoost wykorzystujemy zbiór walidacyjny do procesu wczesnego zatrzymywania (\textit{ang. Early stopping}), natomiast dla modeli BMR oraz TO korzystamy z tego zbioru jako zbiór treningowy. Następnie dla wszystkich modeli dokonujemy predykcyji na zbiorze testowym i mierzymy skuteczność typowań.

\chapter{Rezultaty}

\chapter{Podsumowanie}

% Referencje
% https://towardsdatascience.com/fraud-detection-with-cost-sensitive-machine-learning-24b8760d35d9
% https://www.youtube.com/watch?v=YCNkxaVDiA0
% https://www.slideshare.net/albahnsen/correa-bahnsen-alejandroanalytics2013slideshare - flow of transactions
% https://scikit-learn.org/stable/modules/ensemble.html
% https://github.com/dmlc/xgboost/blob/master/CITATION

% TODO:
% Resampling to LR

\end{document}