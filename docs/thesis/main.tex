\documentclass{book}

\usepackage{amsmath}
\usepackage{listings}

\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{makecell}
\setcellgapes{5pt}

\usepackage[utf8]{inputenc}
\usepackage{polski}

\DeclareMathOperator*{\argmin}{arg\,min}

\title{Detekcja oszustw z wykorzystaniem metod wrażliwych na koszt}
\author{Patryk Wielopolski}

\begin{document}
	
	\newcommand{\htx}{h_{\theta}(\boldsymbol{x_i})}
	\newcommand{\es}{\mathcal{S}}
	\newcommand{\ef}{\mathcal{F}}
	\newcommand{\iks}{\boldsymbol{x}}
	\newcommand{\bes}{\boldsymbol{S}}
	\newcommand{\yht}[1]{y_i^{(#1)}}
	\newcommand{\ylab}[2]{\text{#1}_{\text{#2}}}
	
	\newenvironment{talign}
	{\align}
	{\endalign}
	
	\newenvironment{talign*}
	{\csname align*\endcsname}
	{\endalign}

\maketitle

\chapter{Wstęp}
	- Rosnąca ilość transakcji kartami kredytowymi
	- Rosnący poziom fraudów na świecie
	
	- Flow transakcji oraz umiejscowienie systemu do detekcji fraudów
	- Aktualna sytuacja if-then + predicitve models
	
	If-then:
	- więcej niż 4 wypłaty z bankomatu w ciągu godziny
	- więcej niż 2 transakcje w ciągu 5 minut
	- transakcja w sklepie karta a następna zaraz w internecie
	
	Jeżeli więcej niż 1 reguła jest spełniona to odmowa transakcji. Pojawiają się problemy z niewykrywaniem nowych reguł oraz możliwe jest tworzenie tylko prostych reguł. Z drugiej strony są one proste do implementacji oraz interpretacji.
	

\chapter{Wprowadzenie teoretyczne}

W tej części zostaną wprowadzone wszelkie potrzebne miary skuteczności modeli oraz modele predykcyjne, które zostaną wykorzystane do przeprowadzenia eksperymentu. 

Modele predykcyjne zostały podzielone na dwie kategorie: standardowe oraz wrażliwe na koszt. Pierwsze z nich są powszechnie wykorzystywane w standardowych aplikacjach. Drugie z nich dzielą się na dwie podkategorie - \textit{Cost Sensitive Training} oraz \textit{Cost Sensitive Classification}.

\section{Miary skuteczności modeli}

\subsection{Macierz pomyłek}

W tej sekcji zdefiniujemy macierz pomyłek.
\begin{table}[h]
	\begin{center}
		\makegapedcells
		\begin{tabular}{cc|cc}
			\multicolumn{2}{c}{}     &   \multicolumn{2}{c}{Predykcja} \\
			&            &   Oszustwo &   Normalna     \\ 
			\cline{2-4}
			\multirow{2}{*}{\rotatebox[origin=c]{90}{Prawda}} & Oszustwo   & TP         & FN              \\
			& Normalna   & FP         & TN              \\ 
			\cline{2-4}
		\end{tabular}
	\end{center}
	\caption{Macierz pomyłek}
	\label{macierz-pomylek}
\end{table}


Na podstawie podanej macierzy pomyłek w tabeli \ref{macierz-pomylek} definiujemy następujące miary skuteczności modeli:

$$ \text{Skuteczność} = \frac{TP + TN}{TP + FP + FN + TN} $$
$$ \text{Precyzja} = \frac{TP}{TP + FP} $$
$$ \text{Czułość}= \frac{TP}{TP + FN} $$
$$ \text{F1 Score} = 2 \cdot \frac{\text{Precyzja} \cdot \text{Czułość}}{\text{Precyzja} + \text{Czułość}} $$

\subsection{Miary skuteczności modeli wrażliwe na koszt}

	Motywacją do powstania miar wrażliwych na koszt jest rzeczywista ewaluacja modeli. Podstawowe metryki nie uwzględniają różnicy w kosztach pomyłki dla fp i fn. Ponadto koszt fraudów znacząco różni się w zależności od przypadku.

	W celu wprowadzenia potrzebnych metryk potrzebujemy wprowadzić tzw. macierz kosztu, która jest zaprezentowana w tabeli \ref{macierz-kosztu}, gdzie poszczególne komórki oznacza odpowiadające wartość kosztu predykcji. 
	\begin{table}[h]
		\begin{center}
			\makegapedcells
			\begin{tabular}{cc|cc}
				\multicolumn{2}{c}{}     &   \multicolumn{2}{c}{Predykcja} \\
				&            &   Oszustwo &   Normalna     \\ 
				\cline{2-4}
				\multirow{2}{*}{\rotatebox[origin=c]{90}{Prawda}} & Oszustwo   & $C_{TP_{i}}$         & $C_{FN_{i}}$              \\
				& Normalna   & $C_{FP_{i}}$         & $C_{TN_{i}}$              \\ 
				\cline{2-4}
			\end{tabular}
		\end{center}
		\caption{Macierz kosztu}
		\label{macierz-kosztu}
	\end{table}
	Następnie definiujemy następującą wartość:
	$$ \text{Koszt}(f(\iks_{i}^{*})) = y_i (c_i C_{TP_i} + (1-c_i)C_{FN_i}) + (1-y_i)(c_i C_{FP_i} + (1-c_i)C_{TN_i}) \text{,}$$
	gdzie 
	\begin{itemize}
		\item $\iks_{i}^{*} = [\iks_i, C_{TP_{i}}, C_{FP_{i}}, C_{FN_{i}}, C_{TN_{i}}]$ - wektor zawierający wartości cech i-tej obserwacji rozszerzony o koszt klasyfikacji
		\item $C_{\cdot}$ - koszt klasyfikacji i-tej obserwacji
		\item $f(\cdot)$ - model predykcyjny
		\item $y_i$ - prawdziwa wartość i-tej obserwacji
		\item $c_i$ - predykcja dla i-tej obserwacji
	\end{itemize}{}
    Następnie wprowadzamy następujące miary skuteczności modeli:
	\begin{equation}
		\label{koszt-calkowity}
		\text{Koszt całkowity}(f(\boldsymbol{S})) = \sum_{i=1}^{N}\text{Cost}(f(\boldsymbol{x}_{i}^{*}))
	\end{equation} 
	\begin{equation}
		\text{Oszczędności} = \frac{\text{Koszt}_{l}(\bes) - \text{Koszt}(f(\bes))}{\text{Koszt}_{l}(\bes)}
	\end{equation}
	gdzie
	\begin{itemize}
		\item $ \bes $ - data set
		\item $ \text{Koszt}_0 = min\{\text{Cost}(f_{0}(\bes), \text{Koszt}(f_{1}(\bes)\} $
		\item $ f_{a}(\bes) = \boldsymbol{a} $ gdzie $a \in \{0,1\}$
	\end{itemize}{}
	Wartość $ f_{a}(\bes)$ możemy rozumieć jako przypadek naiwnego modelu, który wszystkim obserwacjom przyznaje wartość $a$. Natomiast $ \text{Koszt}_0 $ oznacza wybranie naiwnego klasyfikatora, który generuje mniejsze koszty. Zatem ostatecznie Oszczędności możemy rozumieć jako procentową wartość o ile testowany model jest lepszy od naiwnego klasyfikatora.
	
	% TODO: Analiza wartości minimalnych oraz maksymalnych Kosztu całkowitego oraz Oszczędności. 

\section{Standardowe modele}

	% TODO: Kilka słów o MLu w ogólności
	
	With judicious choices for yi, we may express a variety of tasks, such as regression, classification, and ranking. The task of training the model amounts to finding the best parameters that best fit the training data xi and labels yi
	
	. In order to train the model, we need to define the objective function to measure how well the model fit the training data.
	
	A salient characteristic of objective functions is that they consist two parts: training loss and regularization term:

	
	where L
	is the training loss function, and is the regularization term. The training loss measures how predictive our model is with respect to the training data. A common choice of L is the mean squared error, which is given by

\subsection{Regresja logistyczna}
\label{reg-log}
	Regresja logistyczna należy do jednego z najbardziej podstawowych modeli statystycznych używanych do problemów klasyfikacyjnych. 
	\begin{equation}
		\hat{p} = P(y=1|\boldsymbol{x_i}) = h_{\theta}(\boldsymbol{x_i}) = g\left(\sum_{j=1}^k \theta^{(j)}x_i^{(j)} \right)
	\end{equation} 
	Standardowa funkcja straty przyjmuje następującą postać:
	$$ J(\theta) = \frac{1}{N} \sum_{i=1}^N J_i(\theta) $$
	gdzie funkcja $g(z)$ jest funkcją łączącą typu \textit{logit} i przyjmuje postać 
	$$ g(z) = \frac{1}{(1+e^{-z})} $$
	Natomiast 
	\begin{equation}
	\label{c-e}
		J_i(\theta) = -y_i log(h_{\theta}(\boldsymbol{x_i})) - (1-y_i) log(1 - h_{\theta}(\boldsymbol{x_i}))
	\end{equation}
	$$  $$
	 to standardowa entropia krzyżowa.

	% Wykres entropii krzyżowej

    Korzystając z wykresu ... możemy zauważyć, że koszt klasyfikacji przyjmuje następujące wartości:
	$$
	J_i(\theta) \approx \left\{
	\begin{array}{rl}
	0, &\mbox{if $y_i \approx \htx$}, \\
	\infty, &\mbox{if $y_i \approx (1 - \htx)$}.
	\end{array}{}
	\right.
	$$
	To znaczy, że w przypadku prawidłowego zaklasyfikowania danej obserwacji funkcja kosztu przyjmuje wartość bliską zeru, natomiast w przypadku pomyłki nieskończoności. Zatem stąd możemy wywnioskować, że koszty popełnienia bądź niepopełnienia błędu są następujące:
	$$ C_{TP_i} = C_{TN_i} \approx 0 $$
	$$ C_{FP_i} = C_{FN_i} \approx \infty $$
	Porównując otrzymane rezultaty z macierzą kosztów możemy zauważyć, że te wartości znacząco odbiegają od tego co w rzeczywistości chcemy otrzymać. Stąd powstaje motywacja, aby zmodyfikować podaną funkcję celu i stworzyć regresję logistyczną wrażliwą na koszt, która będzie optymalizować właściwe dla Nas wartości.
\subsection{Drzewo decyzyjne}
\label{drzewo}

	Drzewo klasyfikacyjne to przykład jednego z rodzaju drzew decyzyjnych, którego celem jest znalezienie najlepszego rozróżnienia pomiędzy klasami. W ogólności drzewo decyzyjne składa się z zestawu reguł.
	
	Drzewo składa się z węzłów, które są reprezentowane przez parę $(\iks^j, l^j)$, która oznacza podział zbioru obserwacji $\es$ na dwa zbiory: $\es^{l}$ oraz $\es^{r}$ względem wektora obserwacji $\iks$ oraz progu decyzyjnego $\l^j$ w następujący sposób:
	$$ \es^l = \{ \iks^* : \iks^* \in \es \land x^j_i \leq l^j \} \text{,} $$
	$$ \es^r = \{ \iks^* : \iks^* \in \es \land x^j_i > l^j \} \text{,} $$
	gdzie $\iks^j$ reprezentuje $j$-ty atrybut wektora $\iks$. Ponadto $\l^j$ jest wartością taką, że $\min{\iks^j} \leq l^j < \max{\iks^j}$. Ponadto warto zauważyć, że $\es^l \cup \es^r = \es$, co oznacza, że nasz podział rozdziela wektor obserwacji na dokładnie dwa rozłączne zbiory.
	Po znalezieniu optymalnego podziału zliczamy ilość pozytywnych próbek:
	$$ \es_1  = \{ \iks^* : \iks^* \in \es \land y_i = 1 \} \text{,} $$
	a następnie zliczamy procent pozytywnych próbek jako:
	$$ \pi_1 = \frac{|\es_1|}{|\es|} \text{.}$$
	Następnie dla każdego z liści jest obliczana wielkość jego zanieczyszczenia.
	\begin{itemize}
		\item Misclassification: $I_m(\pi_1) = 1 - \max(\pi_1, 1 - \pi_1)$
		\item Entropy: $I_e(\pi_1) = -\pi_1 \log(\pi_1) - (1 - \pi_1) \log (1 - \pi_1)$
		\item Gini: $I_g(\pi_1) = 2 \pi_1 (1 - \pi_1)$
	\end{itemize}{}
	Następnie dla każdego proponowanego podziału dla danej reguły $(\iks^j, l^j)$ liczony jest przyrost czystości w następujący sposób:
	$$ \text{Gain}(\iks^j, l^j) = I(\pi_1) - \frac{|\es^l|}{|\es|} I(\pi_1^l) - \frac{|\es^r|}{|\es|} I(\pi_1^r) \text{,}$$
	gdzie $I(\pi_1)$ może być dowolną z zaproponowanych miar zanieczyszczenia.
	Ostatecznie wybiera się ten podział, który maksymalizuje przyrost czystości, a następnie dzieli się zbiór $\es$ na podzbiory $\es^l$ i $\es^r$.
	W taki sposób jest pokonywany pojedynczy podział zbioru dla konkretnego węzła. Całe drzewo tworzy się poprzez kolejne podziały węzłów aż do momentu dotarcia przez algorytm do kryterium stopu.
	
	% Dopisać kryteria stopu?
	% Przycinanie drzew 

\subsection{Las losowy}
	Kolejne modele są przedstawicielami szerokiej klasy metod \textit{ensemble}, których celem jest złożenie predykcji wielu klasyfikatorów bazowych, aby poprawić generalizację pojedynczego estymatora. Wśród nich wyróżniamy dwie główne kategorie. Pierwsza z nich to metody uśredniania, które polegają na zbudowaniu wielu niezależnych klasyfikatorów, a następnie uśrednianie wyników predykcji. Przedstawicielem tej kategorii jest las losowy. Natomiast druga polega na iteracyjnym budowaniu kolejnych modeli, które próbują zredukować obciążenie poprzednika. Bardzo powszechnie znanym reprezentantem jest algorytm XGBoost, którym zajmiemy się w następnym podrozdziale.
		
	Metody \textit{ensemble} wykorzystują metody próbkowania w celu utworzenia różnych klasyfikatorów bazowych, aby następnie dokonać ostatecznej predykcji. Metody te są używane, aby zredukować wariancję klasyfikatora bazowego (zazwyczaj drzewa decyzyjnego) poprzez losowe dobieranie próbki i/lub zmiennych, na których model będzie uczony. W wielu przypadkach stworzenie modelu opartego o \textit{bagging} jest znacznie prostsze, ponieważ wymaga jedynie zmiany próbkowania danych bez naruszania modelu bazowego, natomiast metody typu \text{boosting} wymagają zmiany całego algorytmu. Z licznych obserwacji wynika, że pierwsza z metod dużo lepiej radzi sobie mają jako bazowe klasyfikatory złożone modele, w przeciwieństwie do drugiej, która zazwyczaj najlepiej performuje wykorzystując proste modele (np. płytkie drzewa decyzyjne, tzn. o małej głębokości).
	
	% TODO: Złączyć oba opisy w jeden.
	
	Przykładowe metody losowania próbek do modeli bazowych:
	\begin{itemize}
		\item \textit{Pasting} - losowanie obserwacji bez powtórzeń
		\item \textit{Bagging} - losowanie obserwacji z powtórzeniami
		\item \textit{Random Subspaces} - losowanie podzbioru zmiennych
		\item \textit{Random Patches} - losowanie podzbioru zmiennych oraz obserwacji 
	\end{itemize}
	
	
	W przypadku lasu losowego proces losowania próbek jest podzielony na dwie fazy. Pierwsza z nich polega na próbkowaniu z powtórzeniami obserwacji ze zbioru treningowego dla każdego z osobnych estymatorów bazowych. Następnie podczas fazy tworzenia kolejnych węzłów w drzewach wybierany jest losowy podzbiór zmiennych, które mogą być w tym kroku wykorzystane. 
	
	Celem tych dwóch różnych źródeł losowości jest redukcja wariancji lasu. Pojedyncze drzewa mają tendencję do zbytniego dopasowywania się do danych, zatem losowanie poszczególnych zmiennych w każdym kolejnym węźle pomaga to zredukować. Natomiast losowanie różnych próbek do każdego z klasyfikatorów pozwala na stworzenie lekko odmiennych modeli bazowych.

\subsection{XGBoost}
	Tak jak wspomnieliśmy w poprzednim rozdziale algorytm XGBoost jest przykładem klasyfikatora, który w iteracyjny sposób tworzy kolejne bazowe klasyfikatory. W przypadku tego algorytmu jako klasyfikator bazowy wykorzystujemy implementację drzew decyzyjnych typu CART, które nieznacznie różnią się od standardowych drzew decyzyjnych opisywanych w \ref{drzewo}, ponieważ liść drzewa jest rozszerzony o wartość rzeczywistą, która reprezentuje decyzję modelu. Ponieważ jest to złożenie wielu klasyfikatorów, to możemy zapisać nasz model w następującej postaci:
	$$ \hat{y_i} = \sum_{k=1}^K f_k(x_i) \text{,} f_k \in \ef \text{,} $$
	gdzie $K$ oznacza liczbę drzew, $f$ funkcje z przestrzeni $\ef$ wszystkich możliwych drzew CART.
	Zatem funkcją, którą będziemy optymalizować przyjmuje następującą postać:
	\begin{equation}
	\label{Obj}
		\text{Obj}(\theta) = \sum_{i=1}^{n} l(y_i, \yht{t}) + \sum_{k=1}^{K} \Omega(f_k)
	\end{equation}
	W przypadku klasyfikacji przyjmujemy tak samo jak poprzednio funkcję entropii krzyżowej (\ref{c-e}).
	Patrząc na postać modelu nie różni się ona niczym od lasu losowego. Zatem różnica między tymi modelami polega na sposobie trenowania drzew, który pokrótce opiszemy.
	
	Ponieważ naszym modelem bazowym jest drzewo, to nie jesteśmy w stanie wprost rozwiązać zagadnienia optymalizacyjnego poprzez obliczenie gradientu funkcji i iteracyjne znalezienie rozwiązania. W tym przypadku posłużymy się treningiem addytywnym, który polega na iteracyjnym poprawianiem błędów z poprzednich modeli poprzez odpowiednie przydzielanie wag próbkom w kolejnych krokach algorytmu. 
	Oznaczmy wartość predykcji w kroku $t$ jako $\yht{t}$.
	
	 $$ \yht{0} = 0 $$
	 $$ \yht{1} = f_1(x_i)  = \yht{0} + f_1(x_i) $$
	 $$ \yht{2} = f_1(x_i) + f_2(x_i) = \yht{1} + f_2(x_i) $$
	 $$ ... $$
	 $$ \yht{t} = \sum_{k=1}^{t} f_k(x_i) = \yht{t-1} + f_t(x_i) $$
	 
	 Pozostaje zagadnienie jakie drzewo chcemy wybrać w każdym z kroków. Oczywiście takie, które optymalizuje naszą funkcję Obj. Korzystając z powyższych wzorów oraz \ref{Obj} otrzymujemy następującą postać tej funkcji:
	 $$ \sum_{i=1}^{n} l(y_i, \yht{t-1} + f_t(x_i)) + \Omega(f_t) + \text{constant .}$$
	 Korzystając z rozwinięcia szeregu Taylora dla funkcji straty otrzymujemy ogólny wzór:
	 $$ \text{Obj}^{(t)} = \sum_{i=1}^{n} [l(y_i, \yht{t-1}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t) + \text{constant ,} $$
	 gdzie 
	 $$ g_i = \partial_{\yht{t-1}} l(y_i, \yht{t-1}) $$
	 $$ h_i = \partial^2_{\yht{t-1}} l(y_i, \yht{t-1}) $$
	 Zatem po redukcji stałych, które są nieistotne z punktu widzenia optymalizacji otrzymujemy:
	 $$ \sum_{i=1}^{n} [g_i f_t(x_i) + \frac{1}{2} h_i f_t(x_i)] + \Omega(f_t) $$

\section{Cost Dependent Classification}
	Metody \textit{Cost Dependent Classification} są przykładem pierwszego rodzaju modeli wrażliwych na koszt. W przypadku tych metod trening odbywa się dopiero po etapie stworzenia modelu zwracającego prawdopodobieństwa i informacja o koszcie jest uwzględniana dopiero w tej fazie modelowania. Cały proces jest przedstawiony na Rysunku \ref{cdc}. Górna część diagramu przedstawia standardowy proces uczenia modelu predykcyjnego, natomiast dolna część reprezentuje schemat dokonywania predykcji, w którym najpierw estymujemy prawdopodobieństwa dla zbioru testowego, a następnie wykorzystując te wartości oraz koszt klasyfikacji dokonujemy ostatecznej decyzji, czy dana obserwacja jest pozytywna czy negatywna. Warto wspomnieć, że w celu dokonania kolejnego treningu modelu potrzebujemy podzbioru danych, który nie był wykorzystywany do uczenia podstawowego modelu. Najczęściej taki zbiór nazywamy walidacyjnym bądź developerskim. 
	\begin{figure}
		\includegraphics[width=\linewidth]{images/cost_sensitive_classification.png}
		\caption{Schemat przedstawiający proces uczenia klasyfikatora wrażliwego na koszt. Źródło: https://towardsdatascience.com/fraud-detection-with-cost-sensitive-machine-learning-24b8760d35d9}
		\label{cdc}
	\end{figure}
	\subsection{Optymalizacja progu}
		Metoda optymalizacji progu jest popularną metodą wyznaczania odpowiedniego progu prawdopodobieństwa powyżej którego wszystkie obserwacje oznaczamy jako pozytywnie zaklasyfikowane. Może być ona wykorzystywana nie tylko do problemów wrażliwych na koszt, lecz do dowolnie zdefiniowanego zagadnienia, w której wyznaczenie progu jest potrzebne. Jej sformułowanie wygląda następująco
		$$ \argmin_{th \in [0,1]} f(\ylab{y}{true}, \ylab{y}{decision}) \text{,} $$
		gdzie 
		\begin{itemize}
			\item $ f(\dot) $ - funkcja scorująca model, np. skuteczność,
			\item $ \ylab{y}{true} = (c_i)_{i=1}^n $ - wektor prawdziwych oznaczeń ,
			\item $ \ylab{y}{decision} = (p_i > th)_{i=1}^n $ - wektor binarnych odpowiedzi modelu,
			\item $ p_i $ - przewidywana wartość prawdopodobieństwa dla i-tej obserwacji,
			\item $ \text{th} $ - wartość progu decyzyjnego.
		\end{itemize}{}
		W naszym przypadku funkcja $f$ to funkcja kosztu całkowitego (\ref{koszt-calkowity}). Innymi słowy, w tym przypadku będziemy szukać takiego progu decyzyjnego, który zminimalizuje sumaryczną wartość kosztów.
		
		% TODO: Opcjonalne - odwołać się do przypadków wielu minimum. Opisać algorytmiczne wyznaczanie tej wartości.
	\subsection{Bayesian Minimum Risk}
	
	Ryzyko poszczególnych klasyfikacji definiujemy w następujący sposób:
	$$ R(p_1|x_i) = L(p_1|y_1)P(p_1|x_i) + L(p_1|y_0)P(y_0|x_i) \text{,}$$
	$$ R(p_0|x_i) = L(p_0|y_0)P(p_0|x_i) + L(p_0|y_1)P(y_1|x_i) \text{,}$$
	gdzie
	\begin{itemize}
		\item $P(p_1|x_i)$, $P(p_0|x_i)$ - oznacza estymowane przez model prawdopodobieństwo i oczywiście $P(p_0|x) = 1 - P(p_1|x)$,
		\item $L(p_{i}|y_{j})$ oraz $i,j \in \{l,f\}$ - funkcja kosztu,
		\item $x_i$ - i-ta obserwacja.
	\end{itemize}{}
	Klasyfikacja danej obserwacji jest opisana następującą nierównością:
	$$ R(p_1|x_i) \leq R(p_0|x_i)$$
	I oznacza ona, że klasyfikujemy dany przykład jako pozytywny, jeżeli ryzyko takiej decyzji jest mniejsze niż zaklasyfikowania danej obserwacji jako negatywną. 
	Po przeprowadzaniu odpowiednich przekształceń algebraicznych otrzymujemy następujący wzór na klasyfikację przykładu jako pozytywny:
	$$ P(p_1|x_i) \ge \frac{L(p_1|y_0) - L(p_0|y_0)}{L(p_0|y_1) - L(p_1|y_1) - L(p_0|y_0) + L(p_1|y_0)} \text{.}$$
	W przypadku gdy za funkcję kosztu przyjmiemy odpowiednie wartość z macierzy kosztu, to otrzymujemy następujący prób decyzyjny:
	$$ p \ge \frac{C_{FP_i} - C_{TN_i}}{C_{FN_i} - C_{TP_i} - C_{TN_i} + C_{FP_i}} \text{.}$$

\section{Cost Sensitive Training}
	Drugą podgrupą metod wrażliwych na koszt jest \textit{Cost Sensitive Trainig}. Są to metody, które już na etapie treningu modelu biorą pod uwagę koszt związany z klasyfikacją danej obserwacji. Schemat uczenia modelu jest przedstawiony na Rysunku \ref{cst}. Model jako wejście otrzymuje zbiór danych treningowych, następnie dokonuje predykcji i na bazie prawdziwych odpowiedzi oraz kosztów wyznaczana jest skuteczność modelu i kolejno aktualizowane są wagi, a cały proces jest iteracyjnie powtarzany aż do momentu osiągnięcia zadanego kryterium stopu.
	\begin{figure}
		\includegraphics[width=\linewidth]{images/cost_sensitive_training.png}
		\caption{Schemat przedstawiający proces uczenia modelu wrażliwego na koszt. Źródło: https://towardsdatascience.com/fraud-detection-with-cost-sensitive-machine-learning-24b8760d35d9}
		\label{cst}
	\end{figure}	

\subsection{Regresja logistyczna wrażliwa na koszt}
		Pierwszy modelem, który stosunkowo łatwo przystosować do bycia wrażliwym na koszt jest regresja logistyczna. Kontynuując rozważania z podrozdziału \ref{reg-log} chcemy, aby funkcja straty przyjmowała następujące wartości, które odpowiadają wartościom z macierzy kosztu:
		$$
		J^c_i(\theta)=\left\{
		\begin{array}{rl}
		C_{TP_i}, &\mbox{if $y_i = 1$ and $\htx \approx 1$}, \\
		C_{TN_i}, &\mbox{if $y_i = 0$ and $\htx \approx 0$}, \\
		C_{FP_i}, &\mbox{if $y_i = 0$ and $\htx \approx 1$}, \\
		C_{FN_i}, &\mbox{if $y_i = 1$ and $\htx \approx 0$}.
		\end{array}
		\right.
		$$
		W rezultacie funkcją, która zachowuje się w powyższy sposób jest:
		\begin{talign*}
			J^c(\theta) &= \frac{1}{N} \sum_{i=1}^{N} \bigg( y_i \Big( \htx C_{TP_i} + (1 - \htx)C_{FN_i} \Big) \\
			&+ (1-y_i) \Big( \htx C_{FP_i} + (1 - \htx)C_{TN_i} \Big) \bigg)
		\end{talign*}
		% TODO: Wykres
		Następnie standardowo wykorzystując algorytm optymalizujący, który znajdzie odpowiednie współczynniki modelu trenujemy model predykcyjny.
\subsection{Drzewo decyzyjne wrażliwe na koszt}
	Analogicznie jak w przypadku regresji logistycznej w celu wprowadzenia kosztu do treningu drzewa decyzyjnego musimy uzależnić proces powstawania modelu od kosztu danej próbki. Naturalnym miejscem dla drzewa decyzyjnego jest proces podziału danego węzła na kolejne węzły bądź liście. Dlatego definiujemy następującą miarę zanieczyszczenia, która następujący wzór:
	$$ I_c(\es) = min \left\{ Cost(f_0(\es)), Cost(f_1(\es)) \right\} \text{.}$$
	Dodatkowo w przy dokonywaniu predykcji klasyfikacja na wartość pozytywną bądź negatywną następuje wg następującego kryterium:
	$$ f(\es) =  \left\{
		\begin{array}{rl}
			0, &\mbox{jeżeli $\text{Cost}(f_0(\es)) \leq \text{Cost}(f_1(\es))$}, \\
			1, &\mbox{w przeciwnym wypadku},
		\end{array}{}
	\right.
	$$
	gdzie jak zawsze 1 oznacza wartość pozytywną, a 0 negatywną. 
	Z poprzednich rozważań oczywiście możliwe jest stworzenie modeli typu \textit{ensemble}, w których klasyfikatorem bazowym byłoby drzewo decyzyjne wrażliwe na koszt, natomiast jest to poza obszarem badań aktualnej pracy.
\chapter{Eksperyment}
	Celem eksperymentu jest zbadanie jaki wpływ mają na miarę F1 oraz oszczędności mają poszczególne algorytmy.

\section{Dane}
	Do eksperymentu zostanie wykorzystany zbiór danych Credit Card Fraud Detection zawierający 284,807 transakcji w tym zaledwie 492 oszustw. Tabela składa się z 30 kolumn, w tym 28 z nich są to nienazwane, zanonimizowane zmienne, które były wcześniej poddane transformacji PCA (\textit{ang. Principal Component Analysis}), dodatkowo posiadamy informacje dot. czasu transakcji oraz kwoty. 
	
	Mimo tego, że dane zostały poddane anonimizacji można mieć pewne intuicje na temat tego jakie zmienne zostały użyte z zbiorze danych. 
	% TODO: Referencje
	Dane, które standardowo są zbierane podczas procesu dokonywania transakcji, to ID klienta, data dokonania transakcji, kwota, lokalizacja, typ transakcji (przykładowo płatność internetowa, płatność stacjonarna, wypłata z bankomatu), beneficjent transakcji (przykładowo linie lotnicze, hotel, wypożyczalnia samochodów itp.), historyczna informacja dot. czy dana transakcja była oszustwem, wiek klienta, kraj zamieszkania, kod pocztowy, typ karty (przykładowo VISA, MasterCard itp.).
	Na podstawie powyższych zmiennych tworzy się nowe zmienne, które są agregatami czasowymi. W ogólności są to zmienne, które są iloczynem kartezjańskim zbiorów:
	\begin{itemize}
		\item Klient, karta kredytowa;
		\item Typ transakcji, beneficjent transakcji, kategoria beneficjenta, kraj;
		\item W ciągu ostatnich godzin/dni/tygodni/miesięcy;
		\item Ilość, średnia lub suma transakcji.
	\end{itemize}
	Przykładowymi zmiennymi, które powstają w tym procesie są: Ilość transakcji dla tego samego klienta w ciągu ostatnich 6/12/24 godzin, Średnia wartość transakcji dla danego klienta z ostatniego tygodnia. 
	
	
	Rozkład kwoty...
	
\section{Opis eksperymentu}

	Eksperyment został przeprowadzony w następujący sposób:
	50-krotnie dzielimy zbiór danych w proporcjach 50:17:33 na zbiór treningowy, walidacyjny oraz testowy. Następnie uczymy wszystkie modele na zbiorze treningowym. Dla modelu XGBoost wykorzystujemy zbiór walidacyjny do procesu wczesnego zatrzymywania (\textit{ang. Early stopping}), natomiast dla modeli BMR oraz TO korzystamy z tego zbioru jako zbiór treningowy. Następnie dla wszystkich modeli dokonujemy predykcyji na zbiorze testowym i mierzymy skuteczność typowań.

\section{Wyniki}

\chapter{Podsumowanie}

% Referencje
% https://towardsdatascience.com/fraud-detection-with-cost-sensitive-machine-learning-24b8760d35d9
% https://www.youtube.com/watch?v=YCNkxaVDiA0
% https://www.slideshare.net/albahnsen/correa-bahnsen-alejandroanalytics2013slideshare - flow of transactions
% https://scikit-learn.org/stable/modules/ensemble.html
% https://github.com/dmlc/xgboost/blob/master/CITATION

% TODO:
% Resampling to LR

\end{document}